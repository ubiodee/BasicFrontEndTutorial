{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+HGpa+gRFvEBowcMEObDu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ubiodee/BasicFrontEndTutorial/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "h4OssPtncXzj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_postings = pd.read_csv('/job_postings.csv')"
      ],
      "metadata": {
        "id": "tNqTKF_JchfY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "nrrvwS9Zc5to"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ">>> import nltk\n",
        ">>> nltk.download(\"stopwords\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNOzAwyfdd8P",
        "outputId": "fad44d86-1871-41fc-c8b0-46091310f6eb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "Y1_RBOzxfZvN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    # Remove non-alphanumeric characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    # Tokenize text into individual words\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Remove stop words from tokens\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Lemmatize filtered tokens\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
        "    # Return cleaned text as a string\n",
        "    return ' '.join(lemmatized_tokens)"
      ],
      "metadata": {
        "id": "Rvhvo9npfeA4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqi5D3m_Hnc3",
        "outputId": "b9d96205-fc4c-4f2e-fb03-15d342a3e756"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "cJMOuIE-H0E7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_postings['cleaned_text'] = job_postings['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "uLvxCdQrfk0R"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ">>> import nltk\n",
        ">>> nltk.download('punkt')\n",
        ">>> nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "c_Mo_s5Cf2Ve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09ad1cfa-0f8f-4426-f877-cc6fb9ef99d3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inclusive_keywords = ['equal opportunity', 'diversity', 'inclusion', 'minority', 'gender', 'race', 'ethnicity']"
      ],
      "metadata": {
        "id": "nkMmVCiIJSTL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criteria = {'Gender': ['woman', 'man', 'non-binary', 'transgender', 'genderqueer'],\n",
        "            'Race/Ethnicity': ['Black', 'Hispanic/Latinx', 'Asian', 'White', 'Native American', 'Middle Eastern'],\n",
        "            'Age': ['young', 'old', 'experienced', 'fresh'],\n",
        "            'Disability': ['disabled', 'handicapped', 'wheelchair user', 'able-bodied'],\n",
        "            'LGBTQ+': ['lesbian', 'gay', 'bisexual', 'queer', 'trans', 'non-heterosexual', 'non-cisgender']}\n"
      ],
      "metadata": {
        "id": "Z25nL4h5NzFs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scoring = {'Gender': 4,\n",
        "           'Race/Ethnicity': 3,\n",
        "           'Age': 1,\n",
        "           'Disability': 1,\n",
        "           'LGBTQ+': 2}"
      ],
      "metadata": {
        "id": "yzT8y5gwRsbW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inclusive_scores = []\n",
        "\n",
        "# Loop through each job posting and calculate inclusive score\n",
        "for i in range(len(job_postings)):\n",
        "    # Split cleaned text into individual words\n",
        "    words = job_postings.loc[i, 'cleaned_text'].split()\n",
        "    # Calculate total number of words in job posting\n",
        "    total_words = len(words)\n",
        "    # Calculate number of occurrences of each inclusive keyword\n",
        "    keyword_counts = [words.count(keyword.lower()) for keyword in inclusive_keywords]\n",
        "    # Calculate total number of inclusive keywords\n",
        "    total_keywords = sum(keyword_counts)\n",
        "    # Calculate inclusive score as a percentage of total words\n",
        "    inclusive_score = total_keywords / total_words * 100\n",
        "    # Append inclusive score to list\n",
        "    inclusive_scores.append(inclusive_score)\n",
        "\n",
        "# Add inclusive score column to job_postings dataframe\n",
        "job_postings['inclusive_score'] = inclusive_scores"
      ],
      "metadata": {
        "id": "07wJbz68SIvb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inclusive_threshold = 1.0\n",
        "\n",
        "# Filter job postings based on inclusive score threshold\n",
        "inclusive_job_postings = job_postings[job_postings['inclusive_score'] >= inclusive_threshold]"
      ],
      "metadata": {
        "id": "jkM_UJWhSI6y"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}